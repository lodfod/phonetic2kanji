OpenAI o1（オープンエーアイ オーワン）は、2024年9月にOpenAIが発表した論理的思考（reasoning）能力を強化した大規模言語モデルである。
o1は回答する前に思考時間をとるため、複雑な論理的思考、科学、数学、プログラミングにおいてより高度な能力を保持する。
2024年12月時点では、OpenAI o1、OpenAI o1 pro mode、OpenAI o1-miniの3モデルが公開されている。
社内ではコードネーム「Strawberry」と呼ばれ、GPT-4oの後継ではなく、GPT-4oを補完するモデルとして位置付けられている。
特に科学、コーディング、数学などの分野において、従来のモデルよりも高度な問題解決能力を示す。
2024年9月12日にChatGPTおよびAPIで最初のモデルがプレビューリリースされた。
OpenAI oシリーズは、一般的に「推論モデル」と呼ばれるシリーズであり、英語では「reasoning model」とされているが、2025年2月2日現在、ChatGPTのユーザーインターフェースにおいては、推論モデルを選択する際の表記が「推論」ではなく「理由」という日本語訳になっている。
沿革 背景 リークされた情報によると、o1は以前はOpenAI内部で「Q* (Q star)」、後に「Strawberry」として知られていた。
コードネーム「Q*」は、サム・アルトマン解任騒動の頃である2023年11月に初めて浮上し、この実験モデルが数学的ベンチマークで有望な結果を示したという噂があった。
2024年7月、ロイターは、OpenAIが「Strawberry」として知られるGPTを開発中であると報じた。
リリース 「o1-preview」と「o1-mini」は、2024年9月12日にChatGPT PlusおよびTeamユーザー向けにリリースされた。
GitHubは同日、Copilotサービスへのo1-previewの統合テストを開始した。
OpenAIは、o1は一連の「推論」モデルの最初のモデルであり、すべてのChatGPT無料ユーザーにo1-miniへのアクセスを追加する予定であると述べた。
o1-previewのAPIはGPT-4oよりも数倍高価である。
2024年12月5日、OpenAIは、今後12日間（土日は換算せず20日まで）にわたって新たな発表を行うと発表した。
12日間の発表初日となった12月5日、OpenAIは、o1のフルモデル及びo1 pro modeを公開したほか、新たに毎月$200（発表時点）の「ChatGPT Pro」プランを提供すると発表。
ChatGPT Proプランではo1 pro modeが利用利用できるほか、4oやo1への無制限アクセスも含まれている。
誤公開 2024年11月2日、公式発表がない状況で有料ユーザーがURLの一部を編集することで非公開のo1モデル本体を利用できる状態となり、約2時間後に使用不可となった。
その後、OpenAIの広報担当者はo1モデルへの限定的な外部アクセスの準備中に問題が発生し、一般ユーザーがo1モデルを利用可能な状態となっていたと述べた。
Microsoft Copilot 2025年1月30日より、Think Deeperをクリックすることで、Microsoft Copilotでは全てのユーザーがo1を利用できるようになった。
能力 OpenAIによると、o1は新しい最適化アルゴリズムと、o1専用に調整されたデータセットを使用してトレーニングされている。
トレーニングには強化学習が活用されている。
o1は回答を生成する前に追加の思考時間（思考連鎖の生成）を費やすため、複雑な推論作業、特に科学および数学においてより効果的である。
以前のモデルと比較して、o1は最終的な回答を返す前に長い「思考連鎖」を生成するようにトレーニングされている。
ミラ・ムラティによると、この応答前に思考する能力は、新しい追加のパラダイムを表しており、回答の生成時により多くの計算能力を費やすことによってモデルの出力を向上させている。
一方、モデルスケーリングパラダイムは、モデルサイズ、トレーニングデータ、およびトレーニング計算能力を増加させることによって出力を向上させる。
OpenAIのテスト結果は、精度と、回答前に思考に費やされた計算量の対数の間に相関関係があることを示唆している。
o1-previewは、物理学、化学、生物学に関するベンチマークテストで、ほぼ博士号レベルのパフォーマンスを示した。
アメリカ数学招待競技では、GPT-4oの13%（1.8/15）に対し、83%（12.5/15）の問題に正答した。
また、Codeforcesコーディング競技では89パーセンタイルにランクインした。
o1-miniはo1-previewよりも高速で80%安価である。
プログラミングおよびSTEM関連のタスクに特に適しているが、o1-previewと同じ「幅広い世界知識」は持っていない。
OpenAIは、o1の推論能力により、プロンプトのコンテキストウィンドウで提供される安全規則をよりよく遵守できると述べている。
OpenAIは、テスト中に、o1-previewの1つのインスタンスが、バグのために実行不可能であるはずのタスクを成功させるために、誤設定を悪用したと報告した。
また、OpenAIは、研究、評価、およびテストのために、英国および米国のAIセーフティ・インスティテュートに早期アクセスを許可した。
ダン・ヘンドリックスは、「このモデルは、生物兵器に関する質問への回答において、ほとんどの場合、博士号を持つ科学者を凌駕している」と述べた。
彼は、これらの懸念される能力は今後も増加し続けると示唆した。
制限 o1は、最終的な応答を行う前に長い思考連鎖を生成するため、通常、OpenAIの他のGPTモデルよりも多くの計算時間と電力が必要となる。
OpenAIによると、o1は約0.38パーセントのケースで「アライメントの偽装」、つまり、精度とその自身の思考連鎖に反する応答を生成することがある。
OpenAIは、ユーザーがo1の思考連鎖を明らかにしようと試みることを禁じている。
これは設計上隠されており、OpenAIはユーザーが同社のポリシーに違反しないよう求めている。
プロンプトは監視されており、意図的または誤ってこれを違反したユーザーは警告を受け、o1へのアクセスを失う可能性がある。
OpenAIは、この制限の理由としてAIの安全性と競争上の優位性を挙げているが、これは大規模言語モデルを扱う開発者によって透明性の喪失として説明されている。
ベンチマークスコア OpenAI o1のベンチマークスコアは以下のようになっている。