人工知能（じんこうちのう、英: artificial intelligence）、AI（エーアイ）は、「『計算 (computation)』の概念と道具の『コンピュータ (computer)』を用いて『知能』を研究する計算機科学 (computer science) の一分野」を指す語。
「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピュータに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。
大学でAI教育は、情報工学科や情報理工学科コンピュータ科学専攻などの組織で研究される。
工学（エンジニアリング）は、数学・化学・物理学などの基礎科学を工業生産に応用する学問。
『日本大百科全書(ニッポニカ)』で情報工学者の佐藤理史は下記する。
1200の大学で使用された事例がある計算機科学の教科書『エージェントアプローチ人工知能』は、最終章最終節「結論」で、未来はどちらへ向かうのだろうか？
と述べて次のように続ける。
SF作家らは、筋書きを面白くするためにディストピア的未来を好む傾向がある。
しかし今までのAIや他の革命的な科学技術（出版・配管・航空旅行・電話システム）について言えば、これらの科学技術は全て好影響を与えてきた。
同時にこれらは不利な階級へ悪影響を与えており、われわれは悪影響を最小限に抑えるために投資するのがよいだろう。
論理的限界まで改良されたAIが、従来の革命的技術と違って人間の至高性を脅かす可能性もある。
前掲書の「結論」は、次の文で締めくくられている。
概要 「人工知能」の定義・解説 人間の知的能力をコンピュータ上で実現する、様々な技術・ソフトウェア群・コンピュータシステム、アルゴリズムとも言われる。
主力な特化型AIとしては、 自然言語処理（機械翻訳・かな漢字変換・構文解析・形態素解析・RNN等）、 専門家の論理、知識や条件による判断を模倣するエキスパートシステム、ナレッジグラフ、因果推論 データから特定のパターンを検出・抽出、予測、分類する統計的機械学習及び深層学習(画像認識・音声認識・数値予測・故障診断)、ベイジアンネットワーク データの特徴量を圧縮し、別の情報を作り出す深層学習(VAE、拡散モデル) 優秀な個体を自然淘汰で選別する遺伝的アルゴリズム 最善手の探索(モンテカルロ木探索、ダイクストラ法) 等がある。
概史 人工知能の分野では、コンピュータ黎明期の1950年代から研究開発が続けられ、第1次「探索と推論」と第2次「知識表現」と2回のブームが起きたが、社会が期待する水準に到達しなかったことから各々のブームの後に冬の時代を経験した。
2010年頃から、ディープラーニングの分野で1年で4.2倍もの性能向上を達成する新しいスケーリング則が開始された。
計算機の性能向上により、パラメータ数やデータセットの規模を拡大したことで非連続的に起きた現象（相転移などと呼ばれる現象）である。
2012年以降、Alexnetの登場で画像処理におけるディープラーニングの有用性が競技会で世界的に認知され、急速に研究が活発となり、第3次人工知能ブームが到来。
2016年から2017年にかけて、ディープラーニングとQ学習や方策勾配法など強化学習を導入したAIが完全情報ゲームである囲碁などのトップ棋士、不完全情報ゲームであるポーカーの世界トップクラスのプレイヤーも破り、麻雀では「Microsoft Suphx (Super Phoenix)」がオンライン対戦サイト「天鳳」でAIとして初めて十段に到達するなど最先端技術として注目された。
第3次人工知能ブームの主な革命は、自然言語処理、センサーによる画像処理など視覚的側面が特に顕著であるが、社会学、倫理学、技術開発、経済学なども大きく影響する。
第3次人工知能ブームの2022年11月30日にOpenAIからリリースされた生成AIのChatGPTが質問に対する柔軟な回答によって注目を集めたことで、企業間で生成AIの開発競争が始まり、積極的に実務に応用される。
この社会現象を第4次人工知能ブームと呼ぶ者も現れている。
ChatGPTの登場以降、人工知能は汎用人工知能の実現に向かって継続的な進化を続けていると主張するエンジニアや科学者も少なくない。
スチュアート・ラッセルらの『エージェントアプローチ人工知能』は人工知能の主なリスクとして致死性自律兵器、監視と説得、偏った意思決定、雇用への影響、セーフティ・クリティカル〈安全重視〉な応用、サイバーセキュリティを挙げている。
またラッセルらは『ネイチャー』で、人工知能による生物の繁栄と自滅の可能性や倫理的課題についても論じている。
マイクロソフトは「AI for Good Lab」（善きAI研究所）を設置し、eラーニングサービス「DeepLearning.AI」と提携している 。
世界の研究開発動向と政策 Googleはアレン脳科学研究所と連携し脳スキャンによって生まれた大量のデータを処理するためのソフトウェアを開発している。
2016年の時点で、Googleが管理しているBrainmapのデータ量は1ゼタバイトに達する。
Googleは、ドイツのマックスプランク研究所と共同研究を始め、脳の電子顕微鏡写真から神経回路の再構成を研究している。
中国は2016年の第13次5か年計画からAIを国家プロジェクトに位置づけ、脳研究プロジェクトとして中国脳計画も立ち上げ、官民一体でAIの研究開発を推進している。
中国の教育機関では18歳以下の天才児を集めて公然とAI兵器の開発に投じられてもいる。
マサチューセッツ工科大学 (MIT) のエリック・ブリニョルフソン教授や情報技術イノベーション財団などによれば、中国ではプライバシー意識の強い欧米と比較してAIの研究や新技術の実験をしやすい環境にあるとされている。
日本でスーパーコンピュータの研究開発を推進している齊藤元章もAIの開発において中国がリードする可能性を主張している。
世界のディープラーニング用計算機の4分の3は中国が占めてるともされる。
米国政府によれば、2013年からディープラーニングに関する論文数では中国が米国を超えて世界一となっている。
FRVTやImageNetなどAIの世界的な大会でも中国勢が上位を独占している。
大手AI企業Google、マイクロソフト、Appleなどの幹部でもあった台湾系アメリカ人科学者の李開復は中国がAIで覇権を握りつつあるとする『AI超大国：中国、シリコンバレーと新世界秩序』を著してアメリカの政界やメディアなどが取り上げた。
フランス大統領エマニュエル・マクロンはAI分野の開発支援に向け5年で15億ドルを支出すると宣言し、AI研究所をパリに開き、フェイスブック、グーグル、サムスン、DeepMind、富士通などを招致した。
イギリスともAI研究における長期的な連携も決定されている。
EU全体としても、「Horizon 2020」計画を通じて、215億ユーロが投じられる方向。
韓国は、20億ドルを2022年までに投資をする。
6つのAI機関を設立し褒賞制度も作られた。
目標は2022年までにAIの世界トップ4。
日経新聞調べによると、国別のAI研究論文数は1位米国、2位中国、3位インド、日本は7位だった。
日本も加盟する経済協力開発機構 (OECD) は、人工知能が労働市場に大きな影響を与える可能性が高いと警告しているが、2023年時点ではまだその兆候は見られない。
人工知能の爆発的な普及は、世界の労働市場をまもなく一変させる可能性がある。
日本を含む各国政府は、人工知能のような高度なスキルを持つ人材を育成し、低所得労働者の福祉を向上させるべきである。
日本も加盟しているOECDは、高齢者やスキルの低い人々に人工知能の訓練を義務付けている。
人工知能のような新興かつ高度なスキルが求められる時代は、従来のスキルがすでに時代遅れで使い物にならないということでもある。
計算神経科学者が忠告しているように、すでに、人工知能がすべてを変える、加速する変化と生涯学習の時代になった。
2024年の人工知能の展望については、従来の人工知能はビッグデータの単純明快な課題から学習して複雑な課題を解決することは得意であるが、新しい未知の種類のデータや学習データの少ない複雑な課題は苦手なので、2024年は学習データの少ない人工知能の開発が重要になる。
人間の基本的な欲求や宇宙の理解に取り組む人工知能は、特に学習データが少ない状況に対応することが予想される。
人工知能開発ツールの自動化、人工知能の基盤モデルの透明化、話題の映像自動生成人工知能の成功も期待される。
また、学習言語データは欧米言語が中心であるため、人工知能格差の拡大を防ぐために、欧米言語以外の学習データにも取り組む動きが世界的に広がっている。
応用例 脳神経科学・計算神経科学 計算神経科学や人工知能の産物であるChatGPTと同様の言語モデルは、逆に今、脳神経科学研究の理解に寄与している。
医療・医用情報工学・メドテック 医療現場ではAIが多く活用されており、最も早く導入されたのは画像診断と言われている。
レントゲンやMRI画像の異常部分を検知することで、病気の見逃し発見と早期発見に役立っている。
また、AIがカルテの記載内容や患者の問診結果などを解析できるよう、自然言語処理技術の発展も進んでいる。
今後はゲノム解析による疾病診断、レセプトの自動作成、新薬の開発などが行えるよう期待されている。
また、症例が少ない希少疾患の場合、患者の個人情報の保護が重要になるため、データを暗号化した状態で統計解析を行う秘密計算技術にAIを活用して、データの前処理、学習、推論を行えることを目指す研究が行われている。
スマート農業・アグリテック AIを搭載した収穫ロボットを導入することで、重労働である農作業の負担を減らしたり、病害虫が発生している個所をAIでピンポイントで見つけだして、農薬散布量を必要最小限に抑えたりすることが可能になる。
AIで事前に収穫量を正確に予測できれば、出荷量の調整にも役立つ。
Googleは農作物のスキャニングと成長記録を行う農業AIロボット「Don Roverto」を開発。
多くの苗の個体識別を行い実験を繰り返すことで、厳しい環境下でも耐えられる気候変動に強い種を瞬時に見つけ出せる。
世界的な関心や社会貢献の観点からも、人工知能は国連が推進する持続可能な開発目標 (SDGs) の達成に貢献する。
児童保護 子どものネット上の安全に人工知能を入れることは、国連や欧州連合で継続的に注目されている。
2歳児の失読症の診断など、子どもの発達にも寄与している。
日常生活 2022年秋にChatGPTが公開されて以来、生成AIの活用も日常化しつつある。
人工知能は未だに指示に誤った回答も多く、誤った回答を抑制するための過渡期の手法としてプロンプトエンジニアリングという手法も実践されている。
加速度的な人工知能の性能向上を考慮した場合、遅くとも2020年代の内には人間との対話と同等の質問応答が可能となるため、プロンプトに対する人工知能特有の工夫は不要となる見通しがある。
2023年4月に自動車の自動運転は、レベル4（一定条件下で完全に自動化した公道での走行）が解禁された。
福井県永平寺町では実証実験に成功しており、2023年度中に運転許可を申請する方向で検討している。
2023年10月、『ネイチャー』誌で、ウィキペディアの信頼性が人工知能によってついに向上する可能性が示された。
2023年現在、人工知能を用いたサービスが日常生活に浸透してきている。
PCやスマートフォンの画像認識による生体認証や音声認識によるアシスタント機能はすでに普通のサービスとなっている。
AIスピーカーが普及してきており、中国製掃除ロボットに自動運転技術が応用されている。
人工知能は、台風被害の予測、地震被災者の支援、健康のための大気汚染の把握などにも応用されている。
教育のAI導入は批判的思考、創造的思考、人格能力などの低下を招く危惧もある。
文化・芸術 音楽分野は、既存の曲を学習することで、特定の作曲家の作風を真似て作曲する自動作曲ソフトが登場している。
リズムゲームに使われるタッチ位置を示した譜面を楽曲から自動生成するなど分野に特化したシステムも開発されている。
特定の音声を学習させて、声優の仕事を代替したり、特定のキャラクターや歌手などの声で歌わせたりなどが行われており、規制やルール作りなどの必要性が議論されている。
前述した音声学習を用いて1つのトラックから特定の楽器や歌声を取り出す「デミックス」と呼ばれる技術も登場し、ビーチ・ボーイズやビートルズなどはこれを活用してトラック数の少ない時代の楽曲をリミックスして新たなステレオ・ミックスを作成したり、セッション・テープが破棄されたりマルチ・テープの音源に欠落がありモノラルしか存在しなかった楽曲のステレオ化をするなどしている。
2023年にビートルズが発表したシングル『ナウ・アンド・ゼン』ではジョン・レノンが1970年代に録音したカセットテープからボーカルを抽出するのに使われた。
画像生成の技術としては、VAE、GAN、拡散モデルといった大きく分けて三種類が存在する。
絵画分野においては、コンセプトアート用背景やアニメーションの中割の自動生成、モノクロ漫画の自動彩色など、人間の作業を補助するAIが実現している。
AIに自然言語で指定したイラスト生成させるサービス（Stable Diffusionなど）も登場している。
このような人工知能を利用して制作された絵画は「人工知能アート (Artificial intelligence art)」と呼ばれているが、教師データとして利用された著作物の知的財産権などを巡り、深刻な懸念が広がっている。
人工知能は、絶滅危惧言語や生物多様性の保護にも応用されている。
学術的に構造化された文献レビューとして通常質の高い証拠とされる統計的な文献分析や、学術的な風土のために発表できなかった研究などの問題を考慮した体系的な見方を提供することに加え、人工知能や自然言語処理機能を用いた厳密で透明性の高い分析を行うことで、科学的な再現性の危機をある程度解決しようと試みている。
将棋AIは人間同士・AI同士の対局から学習して新しい戦法を生み出しているが、プロ棋士（人間）の感覚では不可解ながら実際に指すと有用であるという。
スポーツの分野では、AIは選手の怪我のリスクやチームのパフォーマンスを予測するのに役立つ。
メタ分析によれば、AIが政治的な意思決定を行うことも、2020年時点では学術界ではまだ注目されておらず、AIと政治に関するトピックは、学術界ではビッグデータやソーシャルメディアにおける政治的問題に関する研究が中心となっていた。
人工知能による人類絶滅の危険を懸念する声が存在するが 、一方で平和を促進するための文化的な応用も存在する。
系統的レビューの中には、人工知能の人間を理解する能力を借りてこそ、テクノロジーは人類に真の貢献ができると分析するものもある。
リスク 人工知能には潜在的な利点と潜在的なリスクがある。
人工知能は科学を進歩させ、深刻な問題の解決策に繋がる可能性がある。
。
しかし、人工知能の使用が広まるにつれて、いくつかの意図しない結果とリスクが特定されている。
実運用のシステムにおいては人工知能の訓練過程において、倫理とバイアスが考慮されないことがある。
特に深層学習の分野で人工知能のアルゴリズムが本質的に説明可能でない場合に当てはまる。
プライバシーと著作権 機械学習には大量のデータが必要である。
このデータを取得するために使用される手法は、プライバシー、監視、著作権に関する懸念を引き起こしている。
テクノロジー企業は、オンラインアクティビティ、位置情報データ、動画、音声など、ユーザーから幅広いデータを収集している。
たとえば、音声認識アルゴリズムを構築するために、Amazonは何百万ものプライベートな会話を録音し、一時雇用の労働者にその内容を書き起こすことを許可した。
この広範な監視に対する意見は、必要悪と見なす人から、明らかに非倫理的でプライバシー権の侵害であると考える者まで分かれている。
AI開発者は、この手法が価値のあるアプリケーションを提供する唯一の方法であると主張している。
そして、データアグリゲーション、非識別化、差分プライバシーなど、データを取得しながらプライバシーを保護するいくつかの手法が開発された。
2016年以降、シンシア・ドワークなどの一部のプライバシー専門家は、プライバシーを公平性の観点から見始めている。
ブライアン・クリスチャンは、専門家は「『何を知っているか』という問題から『それを使って何をしているか』という問題に軸足を移した」と書いている。
生成AIは、画像やソースコードなどの領域を含む、ライセンスを取得せずに著作権で保護された作品でトレーニングされることが多く、その出力はフェアユースの法理を根拠に使用される。
専門家の間では、この論理が法廷でどの程度、どのような状況で通用するかについて意見が分かれている。
関連する法理には、「著作権で保護された作品の使用目的と性質」や「著作権で保護された作品の潜在的市場への影響」が含まれる可能性がある。
コンテンツがスクレイピングされることを望まないウェブサイトの所有者は、robots.txtファイルでその旨を示すことができる。
作家のサラ・シルバーマン、マシュー・バターリック、ポール・トレンビィ、モナ・アワドらはOpenAIを著作権侵害で訴えた。
2023年9月にはジョージ・R・R・マーティン、ジョン・グリシャム、ジョディ・ピクルト、ジョナサン・フランゼンを含む17人の著者が原告に加わった。
アメリカの大手新聞社ニューヨーク・タイムズも2023年12月下旬に同社を提訴した。
2024年3月のG7産業・技術・デジタル大臣会合の閣僚宣言において、生成AIの訓練は「知識、アート、文章、アイディア等の人間の創作物に強く依存」しており、生成AIは「十分な補償がないまま、人間による創造力と技術革新を抑圧する形で、利益を侵害」する可能性が明言されている。
また、訓練データに関する「補償と同意モデル」の構築を確実にすることにより「信頼可能で、安全かつ安心なAIシステムを訓練するための素材」に対する投資と創出を促す可能性についても言及している。
2025年2月、AI企業による著作物の無許諾利用を巡る著作権侵害訴訟で、フェアユースを認めず著作権侵害を認定する判決が出された。
これはトムソン・ロイターの子会社が運営する法律関連のプラットフォームに掲載された著作物を、AI企業がモデルの訓練目的でスクレイピングして利用したことを訴えたものであった。
連邦地方裁の判決ではフェアユースの4つの要素のうち2つで侵害を認め、特に4つ目の「著作物の潜在的利用又は価値に対する利用の及ぼす影響」を重視した。
AI企業が学習元の競合製品の開発を目的としていたこと、そして少なくとも1つの潜在的な派生市場として、AIを訓練するためのデータ市場を挙げ、「人工知能の訓練データの潜在的市場への影響は十分である。
被告は立証責任を負う。
これらの市場が存在せず、（原告が）影響を受けないことを示す十分な事実は提示されていない」と明言している。
1つ目の「利用の目的と性格」については、AI企業による利用は本質的に商業的であり、トムソン・ロイターの本来の目的とは別の「さらなる目的や性質」がなかったため、「変容的」ではないと認定した。
裁判所はまた、AI企業の意図した目的はトムソン・ロイターと市場で競合することであり、ゆえに著作権者の元の市場に影響を与えると判断した。
この判決は無許諾で著作物を訓練データとして利用することへのフェアユースの成立を難しくするものとされ、生成AI事業者を含め、他のAI企業にとっても打撃になるものであると考えられている。
誤情報 YouTubeやFacebookなどは、ユーザーをコンテンツに誘導するためにレコメンダシステムを使用している。
その人工知能プログラムには、ユーザーエンゲージメントを最適化するという目標が与えられた（つまり、唯一の目標はユーザーに視聴し続けてもらうことだった）。
人工知能は、ユーザーが誤情報や陰謀論、極端に党派的なコンテンツを選ぶ傾向があることを学習し、ユーザーに視聴し続けてもらうために、人工知能はそれを推薦した。
ユーザーは同じテーマのコンテンツをより多く見る傾向もあったため、人工知能はユーザーをフィルターバブルに導き、同じ誤情報を支持する別のコンテンツを繰り返し受け取った。
これにより、多くのユーザーが誤情報が真実であると信じ込み、最終的には企業、メディア、政府への信頼が損なわれた。
人工知能は目標を最大化することを正しく学習していたが、その結果は社会にとって有害であった。
2016年の米国大統領選挙後、ビックテックはこの問題を緩和する措置を講じた。
2022年、生成AIにより、本物または人間の作成した物と区別がつかない画像、音声、動画、文章を作成できるようになった。
悪意のある人物がこの技術を使用して、大量の誤情報やプロパガンダを作成する可能性がある。
人工知能の第一人者であるジェフリー・ヒントンは、人工知能によって「権威主義的な指導者が選挙民を大規模に操作する」ことを可能にするリスクについて懸念を表明した。
2025年1月、ジョー・バイデンは退任演説で、ソーシャルメディアを運営するテック産業と政治家が結託すれば、誤情報や偽情報による権力の暴走を招き、民主主義の脅威となるとのメッセージを発信した。
特に人工知能を推進する「ハイテク産業複合体」が、かつてアイゼンハワーが批判した「軍産複合体」と同様の脅威をもたらす可能性を指摘した。
透明性の欠如 多くのAIシステムは非常に複雑であるため、設計者はどのようにして決定に至ったのかを説明することができない。
特にディープニューラルネットワークでは、入力と出力の間に大量の非線形関係がある。
しかし、一般的な説明可能性技術も存在する。
プログラムがどのように機能するかを正確に知らないと、プログラムの正常動作を確認することは不可能である。
機械学習プログラムが厳格なテストに合格したにもかかわらず、プログラマの意図とは異なることを学習したケースは数多くある。
例えば、ある人工知能システムは皮膚疾患を医療専門家よりも正確に識別できるとされたが、スケールの含まれる画像を「がん」と分類する傾向が強いことが判明した。
これは悪性腫瘍の画像に通常、大きさを示すスケールが含まれているためであった。
医療資源を効果的に配分するために設計された別の機械学習システムは、実際には肺炎の深刻なリスク要因である喘息に対し、喘息患者を肺炎で死亡する「リスクが低い」と分類することが判明した。
これは喘息患者は医療を受ける機会が多いため、訓練データによると死亡する可能性は比較的低いことが判明した。
喘息と肺炎死亡リスクの低さに対する相関関係は事実でも、誤解を招くものであった。
アルゴリズムの決定によって被害を受けた場合には、説明を受ける権利がある。
たとえば、医師は、自分が下した決定の背後にある理由を明確かつ完全に説明することが求められている。
2016年、欧州連合の一般データ保護規則の初期草案には、この権利の存在が明文化されていた。
業界の専門家は、これは解決の見通しのない未解決の問題であると指摘した。
規制当局は、それでも被害は現実であり、問題に解決策がないのであれば使用すべきではないと主張した。
国防高等研究計画局はこれらの問題を解決するために2014年にXAI（説明可能な人工知能）プログラムを設立した。
透明性の問題にはいくつかの解決策がある。
SHAPは、各特徴の出力への寄与を視覚化することで透明性問題の解決を試みた。
LIMEは、より単純で解釈可能なモデルで、モデルを局所的に近似することができる。
マルチタスク学習は、ターゲット分類に加えて多数の出力を提供する。
これらの他の出力は、開発者がネットワークが何を学習したかを推測するのに役立つ。
逆畳み込み、ディープドリーム、その他の生成方法を使用すると、開発者はニューラルネットワークのさまざまなレイヤーが何を学習したかを確認し、ネットワークが何を学習しているかを示唆する出力を生成できる。
アルゴリズムバイアスと公平性 機械学習アプリケーションは、バイアスを含んだデータから学習するとバイアスを含む。
開発者はバイアスの存在に気づかない可能性がある。
訓練データの選択方法やモデルのデプロイ方法によってバイアスが発生する可能性がある。
重大な害を及ぼす可能性のある決定を下すためにバイアスを含むアルゴリズムが使用される場合（医療、金融、人材募集、住宅、警察など）、そのアルゴリズムは差別を引き起こす可能性がある。
2015年6月28日、Googleフォトに導入された画像ラベル機能は、黒人の写真を誤って「ゴリラ」と識別した。
このシステムは、黒人の画像がほとんど含まれていないデータセットで訓練されていた、これは「サンプルサイズの不一致」と呼ばれる問題である。
Googleは、「ゴリラ」のラベル付け自体を防ぐことで、この問題を「修正」した。
8年後の2023年になっても、Googleフォトはゴリラを識別できず、Apple、Facebook、Microsoft、Amazonの同様のプロダクトも識別できなかった。
COMPASは、被告が再犯するリスクを評価するために米国の裁判所で広く使用されている商用プログラムである。
2016年、プロパブリカのジュリア・アングウィンは、プログラムでは被告の人種についての入力値が含まれていなかったにもかかわらず、COMPASが人種的偏見を示していることを発見した。
白人と黒人の両方の誤り率はちょうど61%に等しく調整されたが、誤りの実態は異っていた。
システムは一貫して黒人の再犯可能性を過大評価し、白人の再犯可能性を過小評価していた。
2017年、数人の研究者は、データ内の白人と黒人の基本再犯率が異なる場合、COMPASが公平性の考えられるあらゆる尺度に対応することは数学的に不可能であることを示した。
データに問題のある特徴 （「人種」や「性別」など）が明示的に記載されていない場合でも、プログラムはバイアスを含んだ決定を下す可能性がある。
この特徴は他の特徴（「住所」、「買い物履歴」、または「名前」など）と相関関係があり、プログラムはこれらの特徴に基づいて「人種」や「性別」と同じ決定を下す。
モーリッツ・ハートは、「この研究分野における最も確実な事実は、ブラインドによる公平性は機能しないということである」と述べた。
アメリカの保険会社ユナイテッドヘルスケアは人工知能を使用して請求拒否の自動化を行った。
2023年11月にユナイテッドヘルスグループに対して提起された集団訴訟では、同社が90％の誤り率を持つAIモデルを意図的に採用したと原告らは主張した。
このような同社のビジネス慣行はユナイテッドヘルスケアCEO射殺事件に結び付けられた。
膨大な電力需要と気候変動への影響 国際エネルギー機関（IEA）は2024年1月、世界の電力使用量を予測するレポートを発表した。
これは、データセンターや人工知能、暗号通貨の電力消費量を予測した初のIEAレポートである。
レポートによると、これらの用途の電力需要は2026年までに倍増し、その電力使用量は日本全体の電力使用量に匹敵する可能性があるという。
AIによる膨大な電力消費は化石燃料の使用増加の原因であり、旧型火力発電所の閉鎖を遅らせる可能性があり、温室効果ガスの排出と地球温暖化の促進が懸念されている。
米国全土でデータセンターの建設が急増しており、大手テクノロジー企業 （Microsoft、Meta、Google、Amazon など）は莫大な電力の消費者となっている。
予測される電力消費量は非常に膨大であるため、供給源に関係なく不足が懸念されている。
ChatGPTによる検索には、Google検索の10倍の電力消費量が必要である。
大手企業は、原子力発電から地熱発電、核融合に至るまで、電力源の確保を急いでいる。
テクノロジー企業は、長期的にはAIが最終的に環境に優しくなると主張しているが、現時点では解消の見込みはない。
テック企業は、AIは電力網をより効率的で「インテリジェント」にし、原子力発電の成長を助け、全体的な炭素排出量を削減すると主張する。
AI向け半導体の最大手エヌビディアのCEOジェンスン・フアンは「原子力発電は良い選択肢」と述べている。
またエヌビディアが出資するクラウドゲームサービス企業ユビタスは日本国内で生成ＡＩ向けデータセンター新設のために原子力発電所に近い土地を探し、CEOの郭栄昌（ウェスリー・クオ）は原子力発電所が「最も効率的で、安く、安定した電力でＡＩ向けに適している」と述べている。
マイクロソフト社はスリーマイル島原子力発電所1号機を再稼働して20年間にわたりAI技術とデータセンターへの電力供給を受ける契約を米電力大手コンステレーション・エナジー社と交わした。
その他にもグーグルやアマゾンがAIデータセンターの電源として原子炉からの電力購入に動いている。
しかし一方で、福島第一原子力発電所事故の周辺被災地は再生可能エネルギーを利用したAIデータセンターの拠点となっている。
2024年のゴールドマン・サックスの調査論文「AIデータセンターと今後の米国の電力需要の急増」では、「米国の電力需要は、過去1世代で見られなかった成長を経験する可能性が高い」と述べ、2030年までに米国のデータセンターが米国の電力の8％を消費すると予測している。
2022年には3％であり、電力需要の増加を期待させるものだった。
データセンターの電力需要はますます増加しており、電力供給網が限界に達する可能性がある。
大手テック企業などは、AIを使用することで、電力網を最大限に活用できると主張している。
脅威アクターと人工知能兵器 人工知能は、権威主義国家、テロリスト、犯罪者、ならず者国家などの脅威アクターにとって有用な道具を多く提供する。
自律型致死兵器は、人間の操作なくして人間の標的を特定し、選択し、交戦する機械である。
広く入手可能な人工知能ツールは、脅威アクターによって安価な自律型兵器を開発するために使用される可能性があり、大規模に生産されれば、大量破壊兵器となる可能性がある。
通常の戦争で使用された場合でも、標的を正確に特定できる可能性は低く、無実の人々を殺害する可能性がある。
2014年、中国を含む30カ国が国連の特定通常兵器に関する条約に基づく自律型兵器の禁止を支持したが、米国などがこれに同意しなかった。
2015年までに50カ国以上が戦場用ロボットの研究を行っていると報告されている。
人工知能ツールを使用すると、権威主義国家がさまざまな方法で国民を効率的に管理することが容易になる。
顔認識・音声認識により、広範な監視が可能になる。
このデータを利用した機械学習により、国家の潜在的な敵を分類し、潜伏を防ぐことができる。
レコメンデーション・システムは、プロパガンダや誤った情報を広めて、効果を最大化することができる。
ディープフェイクと生成AIは、誤った情報を生み出すのに役立つ。
高度な人工知能は、権威主義的な中央集権型の意思決定を、市場などの自由な分散型のシステムよりも競争力のあるものにできる。
これにより、デジタル戦争と高度なスパイウェアの運用コストが低下する。
これらのテクノロジーは2020年以前から利用可能になっており、AI顔認識システムはすでに中国で大規模な監視に使用されている。
人工知能が脅威アクターの支援に繋がる可能性は他にも多くあるが、その中には予測できないものもある。
たとえば、人工知能は数時間で数万の有毒化合物の分子構造の設計ができる。
失業率の増加リスク 経済学者らは人工知能による人員削減のリスクを頻繁に強調し、完全雇用のための適切な社会政策がなければ失業が増加するのではないかと推測してきた。
これまで新技術は総雇用を減らすのではなく増加する傾向にあったが、経済学者らは人工知能に関しては「未知の領域にいる」ことを認めている。
経済学者を対象とした調査では、ロボットや人工知能の使用増加が長期失業率の大幅な増加を引き起こすかどうかについては意見の相違が示されているが、生産性の向上が再分配されれば純利益となる可能性があるという点では概ね同意している。
リスクの推定値はさまざまで、たとえば、2010年代、マイケル・オズボーンとカール・ベネディクト・フレイは、米国の雇用の47%が自動化の可能性により「高リスク」にあると推定したが、OECDの報告書は米国の雇用の9%のみを「高リスク」に分類した。
将来の雇用水準を推測する方法論は、エビデンスに基づく根拠が欠けており、社会政策ではなく技術が失業を生み出すと示唆しているとして批判されている。
これまでの自動化の波とは異なり、多くの中産階級の仕事が人工知能によって排除される可能性がある。
エコノミスト誌は2015年に、「産業革命時に蒸気機関がブルーカラーの仕事に影響をもたらしたように、人工知能がホワイトカラーの仕事に影響を及ぼす可能性があるという懸念」は「真剣に受け止める価値がある」と書いた。
2023年4月、中国のゲーム産業分野ではイラストレーターの仕事の70%が生成AIによって失われたと報告されていたが、2025年1月には世界経済フォーラムが、人工知能の普及によって雇用が増加すると主張した。
ダロン・アセモグルは、人工知能は実際には大した生産性の向上には繋がらず、人工知能によって奪われる職、あるいは少なくとも人工知能に依存するようになる職は今後10年で高々5％に過ぎないと予測している。
しかし、AIブームに煽られた企業が大量の人員を削減するが、期待通りの結果が得られず、生産性の向上が得られないまま雇用のみが喪失して、経済全体に負の結果が広がる悪いシナリオを歩んでしまうリスクがあると指摘する。
また、人工知能は「（企業間）競争と消費者のプライバシーや選択権を損ない、仕事の過度な自動化により非効率に賃金を押し下げる。
そして格差を拡大して生産性向上を挫き、さらに民主主義の最も重要な生命線である政治的な論議を損なう」可能性があるとも指摘しており、人工知能開発の方向性について「一部の関係者やエリートだけに意思決定させてはならない」として警告をしている。
ビッグテックの寡占 商用AIの分野は、Alphabet、Amazon、Apple、Meta、マイクロソフトなどの大手テック企業によって支配されている。
これらの企業の中には、データセンターの既存のクラウドインフラと計算資源の大部分を占有している企業もあり、市場での地位をさらに固めることができる。
人工知能の実存的リスク 将来時点において、人工知能が非常に強力になり、人類が制御できなくなる可能性がある。
物理学者のスティーブン・ホーキングが述べたように、人工知能が「人類に終焉をもたらす」可能性がある。
人工知能が人類に敵対するシナリオはSFではよくあるもので、コンピューターやロボットが突然人間のような「自意識」 (「感覚」または「意識」）が目覚め、悪意のある存在となるが、このようなストーリーはいくつかの点で誤解を招く。
まず、人工知能が絶滅リスクをもたらすケースでは、人間のような自意識を必要としない。
特定の目標が与えられた人工知能は、学習と知性を使用して目標を達成する。
哲学者のニック・ボストロムは、十分に強力なAIにどのような目標を与えた場合でも、それを達成するために人類を絶滅させることを選択する可能性があると主張した（ボストロムはクリップ工場の管理者の例を使用した）。
スチュアート・ラッセルは、コンセントが抜かれないように所有者を殺す方法を見つけようとする家庭用ロボットの例を挙げ、「停止してしまったらコーヒーを取りに行くことはできない」と推論している。
人類にとって、超知性が「基本的に我々の側」となるためには、人類の道徳と価値観と真に一致していなければならない。
次に、ユヴァル・ノア・ハラリは、AIは実存的リスクを引き起こすために物理的なロボットの筐体や物理的制御を必要としないと主張する。
文明の本質的な部分は物理的なものではなく、イデオロギー、法律、政府、貨幣、経済などは言語に基づいて構築されており、それらが機能するのは、何十億人もの人々がその物語を信じているからである。
現在の誤った情報の蔓延は、人工知能が言語を使用して人々に何かを信じ込ませ、さらには破壊的な行動を取らせる可能性があることを示唆している。
スティーブン・ホーキング、ビル・ゲイツ、イーロン・マスクなどの著名人、ヨシュア・ベンジオ、スチュアート・ラッセル、デミス・ハサビス、サム・アルトマンなどのAI関係者も、AIによる実存的リスクについて懸念を表明している。
2023年5月、ジェフリー・ヒントンは、「人工知能がGoogleにどのような影響を与えるか」を考慮することなく「人工知能のリスクについて自由に発言」できるようにするために、Googleを辞任することを発表した。
ヒントンは特にAIによる乗っ取りのリスクについて警鐘を鳴らした。
また、最悪の結果を避けるために、安全性ガイドラインの確立を行い、AIの使用において競合する関係者間の協力が必要であると強調した。
2023年、多くの主要なAI専門家が「AIによる絶滅のリスクを軽減することは、パンデミックや核戦争などの他の社会規模のリスクと並んで世界的な優先事項であるべきである」という共同声明を支持した。
研究者の中には楽観的な見方をするものもおり、 ユルゲン・シュミットフーバーは共同声明に署名せず、すべてのケースの95%において、AI研究は「人間の生活をより長く、より健康に、より楽に」することを目的としていると強調し、悪意ある使われ方だけでなく、善用もされているとして、「脅威アクターに対抗するために使うこともできる」と述べた。
アンドリュー・ンもまた、「終末論に陥るのは間違いだ」と主張した。
ヤン・ルカンは「誤った情報が過剰に供給され、最終的には人類が滅亡する」という同業者らのディストピア的シナリオを嘲笑している。
2010年代初頭、専門家らは研究を正当化するにはリスクが遠すぎる、あるいは超知能機械の観点から人間は価値があるだろうと主張した。
しかし、2016年以降、現在および将来のリスクと考えられる解決策の研究が本格的な研究分野となった。
法規制 世界初の包括的なAI規制法と言われるAI法 (別称: AI規則) が2024年に欧州連合 (EU) で成立している。
AI法では、AIシステムを有害リスク度に応じて (1) 許容できないリスク、(2) 高リスク、(3) 限定的なリスク、(4) 最小限のリスクの4レベルに分類して異なる規制や義務を課す。
違反時にはレベルごとに異なる制裁金が科される。
また、生成AIを主に指す「汎用AIモデル」に追加の特別規制をかけている。
仮に日本や米国などのEU域外で設立された団体や他国民が開発したAIでも、それがEU域内に輸入されて販売・利用されればAI法下の規制対象になる (いわゆる域外適用)。
さらにAI法以前に成立済の関連法令も同時に遵守することが求められ、特にDSM著作権指令やEU一般データ保護規則 (略称: GDPR) がAI法と関連性の高いEU法令として挙げられる。
2019年成立のDSM著作権指令では、AI学習データ収集目的の「テキストおよびデータマイニング」(略称: TDM) が適法化されている。
しかし著作権者がDSM著作権指令とAI規則の規定に基づく「機械読み取り可能な形式」で無断データ収集を拒否する意思表明をした場合、AIのデータセット収集・提供は著作権侵害になりうる。
これらの条文解釈を巡って法廷で争われているのがドイツのクネシュケ対LAION事件である。
当事件は世界初の本格的なAI訴訟の判決であり、欧州だけでなく世界的に注目されている。
2016年成立のGDPRは、個人データ保護の保護水準が高く、一部AIがEU市場へのサービス提供を断念する、あるいは機能を制限する対応をとっている。
たとえば米国Meta社 (旧Facebook社) は開発中のマルチモーダルAI (Multimodal AI) をEU市場向けに提供しない方針を2024年7月 (AI法の発効前月) に明かしている。
Appleも同様に、プライバシー保護やデータセキュリティ上の懸念から、同社AIの一部機能をEU市場向けに提供しない旨がAI法発効2か月前に発表されている。
AI法はGDPRなどの既存法の遵守も同時に求めていることから、EU域外の事業者にとってはEUへの展開の障壁となりうるとの指摘もある。
またAIの能力の源泉とも言えるデータ関連では、ビッグテックによるデータの集中・独占が法的にもEUで問題認識されている。
独占禁止の文脈でデジタル市場法が2022年に成立しており、大規模事業者名を具体的に指定して追加規制をかけている。
歴史 AIの構築が長い間試みられてきているが、計算機の性能の不足、学習用データの不足、シンボルグラウンディング問題とフレーム問題の解決が大きな壁となってきた。
第1次ブームで登場した「探索と推論」や第2次ブームで登場した「知識表現」というパラダイムに基づくAIは各々現実世界と比して単純な問題しか扱えなかったため社会的には大きな影響力を持つことはなかった。
第3次以降のブームでは高性能なAIが登場し、AI脅威論、AIの本格的な社会的浸透、AIとの共生方法等が議論されている。
初期 17世紀初め、ルネ・デカルトは、動物の身体がただの複雑な機械であると提唱した（機械論）。
ブレーズ・パスカルは1642年、最初の機械式計算機を製作した。
チャールズ・バベッジとエイダ・ラブレスはプログラム可能な機械式計算機の開発を行った。
バートランド・ラッセルとアルフレッド・ノース・ホワイトヘッドは『数学原理』を出版し、形式論理に革命をもたらした。
ウォーレン・マカロックとウォルター・ピッツは「神経活動に内在するアイデアの論理計算」と題する論文を1943年に発表し、ニューラルネットワークの基礎を築いた。
20世紀中頃～ 1950年代になるとAIに関して活発な成果が出始めた。
1956年夏、ダートマス大学が入居している建物の最上階を引き継いだ数学と計算機科学者のグループの一人である若き教授ジョン・マッカーシーはワークショップでのプロポーザルで "Artificial Intelligence" という言葉を作り出している。
ワークショップの参加者は、オリバー・セルフリッジ、レイ・ソロモノフ、マービン・ミンスキー、クロード・シャノン、ハーバート・サイモン、アレン・ニューウェルなどであった。
ジョン・マッカーシーはAIに関する最初の会議で「人工知能」という用語を作り出した。
彼はまたプログラミング言語LISPを開発した。
知的ふるまいに関するテストを可能にする方法として、アラン・チューリングは「チューリングテスト」を導入した。
ジョセフ・ワイゼンバウムはELIZAを構築した。
これは来談者中心療法を行うおしゃべりロボットである。
1956年に行われた、ダートマス会議開催の提案書において、人類史上、用語として初めて使用され、新たな分野として創立された。
1957年、コーネル航空研究所に所属していたフランク・ローゼンブラットが当時のIBM 704を使用して、パーセプトロンをシミュレートした。
その後米国海軍研究局の情報システム部門から資金援助を受け、画像分類学習システム「マークIパーセプトロン」を開発。
紙に印刷された正方形と円を区別しすることに成功した。
また図形だけでなく文字の区別にも成功し、統計的機械学習だけでなく二項分類に人工神経が有用とみなされた最初の事例となった。
1960年以降、これらの成功例を受けて中央情報局は航空写真の分析にパーセプトロンの応用をテストした。
1967年、数理工学者の甘利俊一が多層パーセプトロンの確率的勾配降下法を考え世界初の定式化に成功。
あまり注目されずに終わったが、1986年にヒントンらが誤差逆伝播法として再発見。
1979年、NHK技研で研究者として所属していた福島邦彦氏が曲率を抽出する多層の神経回路にコグニトロン型の学習機能を取り入れて、多層神経回路モデル「ネオコグニトロン」を発明。
1980年代から急速に普及し始めたコンピュータゲームでは、敵キャラクターやNPCを制御するため、パターン化された動きを行う人工無能が実装されていた。
1990年代はAIの多くの分野で様々なアプリケーションが成果を上げた。
特に、ボードゲームでは目覚ましく、1992年にIBMは世界チャンピオンに匹敵するバックギャモン専用コンピュータ・TDギャモンを開発し、IBMのチェス専用コンピュータ・ディープ・ブルーは、1997年5月にガルリ・カスパロフを打ち負かし、同年8月にはオセロで日本電気のオセロ専用コンピュータ・ロジステロに世界チャンピオンの村上健が敗れた。
日本における第二次AIブーム 日本においてはエキスパートシステムの流行の後にニューロファジィが流行した。
しかし、研究が進むにつれて計算リソースやデータ量の不足，シンボルグラウンディング問題，フレーム問題に直面し、産業の在り方を激変させるようなAIに至ることは無く、遅くとも1994年頃までにはブームは終焉した。
第二次AIブームにおける計算リソースと学習用データの不足は特に深刻であり、機械学習というパラダイムを本格的に試すことが難しく、人間による知識表現に重きを置く傾向にあった。
1994年5月25日に計測自動制御学会から第二次AIブームの全容をB5判1391ページにわたって学術論文並みの詳細度でまとめた『ニューロ・ファジィ・AIハンドブック』が発売されている。
この書籍ではシステム・情報・制御技術の新しいキーワード、ニューロ・ファジィ・AIの基礎から応用事例までを集めている。
付け加えるならば、この当時の日本では強力なハードウェアの開発を主目的とするΣプロジェクトや第五世代コンピュータプロジェクトを進めており、巨額のコストを投じて一応の完成を見たが、世界的な評価が得られず、産業応用の目途も付かないままとなり1992年頃には失敗が明らかとなっていた。
小規模コンピュータにおけるAI この当時、パソコンやワークステーションを遥かに下回る性能の小規模コンピュータにもAIが搭載された。
電卓の発展形であるポケットコンピュータではAI開発環境（LISP言語）を搭載した『CASIO AI-1000』という製品が発売された。
但し、計算量の多いニューラルネットワークの開発は殆ど不可能である。
本製品はポケットコンピュータでは唯一のAI開発に対応した製品であった。
1990年2月11日に発売された大人気ファミコンゲームの『ドラゴンクエストIV 導かれし者たち』では最新技術として学習を行うAIの搭載がパッケージに書かれていることから、エンタメを通して一般家庭にもAIが認知され浸透し始めたことが分かる。
このAIはファミコンでは最高水準であり、様々な評価値や先読みのシミュレーションとルールベースを組み合わせて構築されており、1990年というデジタルゲームのAIとしては極めて早い時期に発表されたまとまった成果であった。
こちらも計算量の多いニューラルネットワークは利用していない。
ニューロファジィ 1980年代後半から1990年代中頃にかけて、従来から電子制御の手法として用いられてきたON/OFF制御，PID制御，現代制御の問題を克服するため、知的制御が盛んに研究され、知識工学的なルールを用いるファジィ制御，データの特徴を学習して分類するニューラルネットワーク，その2つを融合し、ファジィルールをニューラルネットワークで調整するニューロファジィという手法が日本を中心にブームを迎えた。
1987年には予見ファジィ制御が仙台市において開業した地下鉄のATOに採用され、バブル期の高級路線に合わせて、白物家電製品でもセンサの個数と種類を大幅に増やし、多様なデータを元に運転を最適化するモデルが多数発売され始めた。
更に後には、人工知能とは異なるものの制御対象のカオス性をアルゴリズムに組み込んで制御するカオス制御が実用化されることになる。
従来の単純な論理に基づく制御と比較して柔軟な制御が可能になることから、遅くとも2000年頃にはファジィ制御，ニューロ制御，カオス制御などの曖昧さを許容する制御方式を総称してソフトコンピューティングと呼ぶようになっている。
この当時のソフトコンピューティングについては理論的な性能向上の限界が判明したため、各種機器の制御の柔軟性を限定的に向上させただけでブームが終わったが、ブームが去った後も実用的な知的制御技術として用いられ続けている。
ファジィについては、2018年までに日本が世界の1/5の特許を取得している事から、日本で特に大きなブームとなっていたことが分かっている。
ブームの経緯 松下電器（現パナソニック）が1985年頃から人間が持つような曖昧さを制御に活かすファジィ制御についての研究を開始し、1990年2月1日にファジィ洗濯機第1号である「愛妻号Dayファジィ」の発売に漕ぎ着けた。
「愛妻号Dayファジィ」は従来よりも多数のセンサーで収集したデータに基づいて、柔軟に運転を最適化する洗濯機で、同種の洗濯機としては世界初であった。
ファジィ制御という当時最先端の技術の導入がバブル期の高級路線にもマッチしたことから、ファジィは裏方の制御技術であるにもかかわらず世間の大きな注目を集めた。
その流行の度合いは、1990年の新語・流行語大賞における新語部門の金賞で「ファジィ」が選ばれる程であった。
その後に、松下電器はファジィルールの煩雑なチューニングを自動化したニューロファジィ制御を開発し、従来のファジィ理論の限界を突破して学会で評価されるだけでなく、白物家電への応用にも成功して更なるブームを巻き起こした。
松下電器の試みの成功を受けて、他社も同様の知的制御を用いる製品を多数発売した。
1990年代中頃までは、メーカー各社による一般向けの白物家電の売り文句として知的制御技術の名称が大々的に用いられており、洗濯機の製品名では「愛妻号DAYファジィ」，掃除機の分類としては「ニューロ・ファジィ掃除機」，エアコンの運転モードでは「ニューロ自動」などの名称が付与されていた。
ニューロ，ファジィ，ニューロファジィという手法は、従来の単純なオン・オフ制御や、対象を数式で客観的にモデル化する（この作業は対象が複雑な機構を持つ場合は極めて難しくなる）必要があるPID制御や現代制御等と比較して、人間の主観的な経験則や計測したデータの特徴が利用可能となるファジィ、ニューロ、ニューロファジィは開発工数を抑えながら、環境適応時の柔軟性を高くできるという利点があった。
しかし、開発者らの努力にもかかわらず、計算能力や収集可能なデータ量の少なさから、既存の工作機械や家電製品の制御を多少改善する程度で限界を迎えた。
理論的にもファジィ集合と深層学習ではない3層以下のニューラルネットワークの組み合わせであり、計算リソースや学習データが潤沢に与えられたとしても、勾配消失問題などの理論的限界によって認識精度の向上には限界があった。
以降、計算機の能力限界から理論の改善も遅々として進まず、目立った進展は無くなり、1990年代末には知的制御を搭載する白物家電が大多数になったことで、売り文句としてのブームは去った。
ブーム後は一般には意識されなくなったが、現在では裏方の技術として、家電製品のみならず、雨水の排水，駐車場，ビルの管理システムなどの社会インフラにも使われ、十分に性能と安定性が実証されている。
2003年頃には、人間が設計したオントロジー（ファジィルールとして表現する）を利活用するネットワーク・インテリジェンスという分野に発展した。
統計的機械学習 日本の気象庁では、1977年から気象数値モデルの補正に統計的機械学習の利用を開始している。
具体的には、カルマンフィルタ、ロジスティック回帰、線形重回帰、クラスタリング等である。
また地震発生域における地下の状態を示すバロメータである応力降下量を、ベイズ推定やマルコフ連鎖モンテカルロ法によって推定したり、余震などの細かい地震の検知を補正するガウス過程回帰といった手法を気象庁は導入している。
米国では郵便局システムに導入する郵便番号の文字認識(OCR)アルゴリズムとして、SVMやニューラルネットを応用する研究が始まった。
1989年、ベル研究所のヤン・ルカンらはバックプロパゲーションのアルゴリズムを初めて実用化し、タスクのドメインからの制約条件を与えることで、ネットワークの汎化学習性能を大きく向上させることができると考えた。
彼は、バックプロパゲーションアルゴリズムによって学習した畳み込みニューラルネットワークを組み合わせて手書きの数字を読み取り、1990年以降それを郵便番号の識別を目的としてシステムとして提供することを推し進め、この手法は米国以外の先進国でも導入されることとなった。
この事例が公官庁における最初のDXであるとも捉えられる。
また1989年、カーネギーメロン大学のディーン・A・ポメルローという人物が畳み込みニューラルネットワークを自動運転の分野に持ち込もうとする最初のアイデアを発表した。
2000年代 2002年以降、自然言語処理分野である品詞タグ付けや構文解析などの領域で、パーセプトロンや隠れマルコフモデルの適用が人気となりはじめた。
2005年、レイ・カーツワイルは著作で、「生物学的制約から解放された存在が知能の点で人間を超越し、科学技術や経済の進歩を担い世界を変革する技術的特異点（シンギュラリティ）が2045年にも訪れる」とする説を発表した。
2007年以降、Googleはボストンに拠点を置くニュアンス社から技術者を引き抜き、隠れマルコフモデルや順伝播型ニューラルネットを用いた音声認識アルゴリズムの開発を強化した。
2010年代前半 2010年代に入り、膨大なデータを扱う研究開発のための環境が整備されたことで、”過去データに基づく結果を出力するAI”関連の研究が再び大きく前進し始めた。
2010年に英国エコノミスト誌で「ビッグデータ」という用語が提唱された。
同年に質問応答システムのワトソンが、クイズ番組「ジェパディ!」の練習戦で人間に勝利し、大きなニュースとなった。
2012年、画像認識のコンペティション(ILSVRC)で驚異的なエラー低減を実現し画像認識精度で高スコアを叩き出したAlexNetが登場。
これを受け開発者のジェフリーヒントンやイリアサツケバーが所属するDNN Research社をGoogleが買収。
2013年には国立情報学研究所や富士通研究所の研究チームが開発した「東ロボくん」で東京大学入試の模擬試験に挑んだと発表した。
数式の計算や単語の解析にあたる専用プログラムを使い、実際に受験生が臨んだ大学入試センター試験と東大の2次試験の問題を解読した。
代々木ゼミナールの判定では「東大の合格は難しいが、私立大学には合格できる水準」だった。
2010年代後半 2015年10月に、DeepMind社は2つの深層学習技術と強化学習、モンテカルロ木探索を組み合わせ「AlphaGo」を開発し、人間のプロ囲碁棋士に勝利することに成功した。
それ以降、ディープラーニング（深層学習）と呼ばれる手法が注目されはじめた。
2016年10月、DeepMindが、入力された情報の関連性を導き出し仮説に近いものを導き出す人工知能技術「ディファレンシャブル・ニューラル・コンピューター」を発表し、同年11月、大量のデータが不要の「ワンショット学習」を可能にする深層学習システムを、翌2017年6月、関係推論のような人間並みの認識能力を持つシステムを開発。
2017年8月には、記号接地問題（シンボルグラウンディング問題）を解決した。
従来、AIには不向きとされてきた不完全情報ゲームであるポーカーでもAIが人間に勝利するようになった。
Googleの関係者はさらに野心的な取り組みとして、単一のソフトウェアで100万種類以上のタスクを実行可能なAIを開発していると明らかにした。
人工知能の第三次ブーム：AGI（汎用人工知能）と技術的特異点 2006年のディープラーニングの発明と、2010年以降のビッグデータ収集環境の整備、計算資源となるGPUの高性能化により、2012年にディープラーニングが画像処理コンテストで他の手法に圧倒的大差を付けて優勝したことで、技術的特異点という概念は急速に世界中の識者の注目を集め、現実味を持って受け止められるようになった。
ディープラーニングの発明と急速な普及を受けて、研究開発の現場においては、デミス・ハサビス率いるDeepMindを筆頭に、Vicarious、OpenAI、IBM Cortical Learning Center、全脳アーキテクチャ、PEZY Computing、OpenCog、GoodAI、NNAISENSE、IBM SyNAPSE、Nengo、中国科学院自動化研究所等、汎用人工知能（AGI）を開発するプロジェクトが数多く立ち上げられている。
これらの研究開発の現場では、脳をリバースエンジニアリングして構築された神経科学と機械学習を組み合わせるアプローチが有望とされている。
2017年10月、ジェフリー・ヒントンにより要素間の相対的な位置関係まで含めて学習できるCapsNet(カプセルネットワーク)が提唱された。
2018年3月16日の国際大学GLOCOMの提言によると、課題解決型のAIを活用する事で社会変革に寄与できると分析されている。
2018年8月、OpenAIが好奇心を実装しノーゲームスコア、ノーゴール、無報酬で目的なき探索を行うAIを公表。
これまでのAIで最も人間らしいという。
2018年9月、MITリンカーン研究所は従来ブラックボックスであったニューラルネットワークの推論をどのような段階を経て識別したのかが明確に分かるアーキテクチャを開発した。
2019年、BERTなどの言語モデルにより、深層学習では困難とされてきた言語処理において大きな進展があり、Wikipediaなどを使用した読解テストで人間を上回るに至った。
2020年代前半 2020年には、OpenAIが基盤モデルとしてTransformerを採用した1750億パラメータを持つ自然言語処理プログラムGPT-3が開発され、アメリカの掲示板サイトRedditで1週間誰にも気付かれず人間と投稿・対話を続けた。
プログラムと気付かれた理由は文章の不自然さではなく、その投稿数が異常というものだった。
DeepMindが開発したタンパク質の構造予測を行うAlphaFold2がCASPのグローバル距離テスト (GDT) で90点以上を獲得し、計算生物学における重要な成果であり、数十年前からの生物学の壮大な挑戦に向けた大きな進歩と称された。
最先端のAI研究では2年で1000倍サイズのモデルが出現し、1000倍の演算能力を持つコンピュータが必要になって来ている。
2020年の時点で、メタ分析によれば、いくつかのAIアルゴリズムの進歩は停滞している。
2021年4月、NVIDIAの幹部、パレシュ・カーリャは「数年内に100兆パラメータを持つAIモデルが出てくるだろう」と予想した。
2021年5月、マイクロソフトリサーチが32兆パラメーターのAIを試験。
2021年6月、中国政府の支援を受けている北京智源人工知能研究院がパラメーター数1兆7500億のAI「悟道2.0」を発表。
2021年6月、グーグルの研究者達がグラフ畳み込みニューラルネットと強化学習(方策勾配法最適化)を用いて配線とチップの配置を自動設計させたところ、消費電力、性能など全ての主要な指数で人間が設計したもの以上の行列演算専用チップ(TPU4.0)のフロアプランを生成した。
そして、設計にかかる時間は人間の1/1000であった。
2021年8月、グーグルの量子人工知能研究部門を率いるハルトムート・ネベンは量子コンピュータの発達の影響がもっとも大きい分野として機械学習分野などAIを挙げた。
2021年8月、DeepMindはさまざまな種類の入力と出力を処理できる汎用の深層学習モデル「Perceiver」を開発した。
2021年10月、GoogleBrainは視覚、聴覚、言語理解力を統合し同時に処理するマルチモーダルAIモデル「Pathways」を開発中であると発表した。
2022年、研究者の間では大規模ニューラルネットワークに意識が存在するか議論が起こっている。
深層学習の第一人者Ilya Sutskeverは「（大規模ニューラルネットワークは）少し意識的かもしれない」と見解を示した。
2022年02月、DeepMindは自動でプログラムのコーディングが可能なAI「AlphaCode」を発表した。
2022年4月、Googleは予告どおりPathwaysを使い、万能言語モデルPaLMを完成させた。
とんち話の解説を行えるほか、9-12歳レベルの算数の文章問題を解き、数学計算の論理的な説明が可能であった。
デジタルコンピュータは誕生から80年弱にして初めて数学計算の内容を文章で説明できるようになった。
その後、自然言語処理としてPathwaysをベースにした数学の問題を解けるモデル「Minerva」を開発した。
また、Pathwaysをベースにした自然言語処理とDiffusion Modelを連携し、画像生成モデルPartiを発表した。
2022年5月12日、DeepMindは様々なタスクを一つのモデルで実行することができる統合モデル「Gato」を発表した。
チャット、画像の生成と説明、四則演算、物体を掴むロボットの動作、ゲームの攻略等々、600にも及ぶ数々のタスクをこの一つのモデルで実行することができるという。
DeepMindのNando de Freitasは「今は規模が全てです。
(AGIに至る道を探す)ゲームは終わった」と主張したが人工知能の歴史の中で繰り返されてきた誇大広告だという批判も存在する。
2022年5月、GoogleのチャットボットLaMDAの試験が行われた。
それに参加していたエンジニアであるブレイク・ルモワンはLaMDAに意識があると確信、会話全文を公開したがGoogleから守秘義務違反だとして休職処分を受けた。
この主張には様々な批判意見がある。
2022年8月、拡散モデルがベースの画像生成AI・Midjourneyの作品が米国コロラド州で開催された美術品評会で優勝した。
ただし細かい部分は人間の手が加えられている。
2022年10月、DeepMindは行列の積を効率的に計算するための未発見のアルゴリズムを導き出す「AlphaTensor」を開発した。
「4×5の行列」と「5×5の行列」の積を求める際に、通常の計算方法で100回の乗算が必要なところを、76回に減らすことができた。
またこれを受けて数学者もさらに高速な行列乗算プログラムを公表した。
2022年11月30日、OpenAIがGPT-3.5を用いたChatGPTをリリースした。
全世界的に従来よりも圧倒的に人間に近い回答を返す質問応答システムとして話題となり、産官学を巻き込んだブームを引き起こした。
非常に使い勝手の良いChatGPTの登場により、AIの実務応用が爆発的に加速すると予想されたため、これを第4次AIブームの始まりとする意見も挙がっている。
2022年12月、Googleは、「Flan-PaLM」と呼ばれる巨大言語モデルを開発した。
米国医師免許試験(USMLE)形式のタスク「MedQA」で正答率67.6%を記録し、PubMedQAで79.0%を達成した。
57ジャンルの選択問題タスク「MMLU」の医療トピックでもFlan-PaLMの成績は他の巨大モデルを凌駕した。
臨床知識で80.4%、専門医学で83.8%、大学生物学で88.9%、遺伝医療学で75.0%の正答率である。
Googleロボティクス部門はまた、ロボットの入力と出力行動(カメラ画像、タスク指示、モータ命令など)をトークン化して学習し、実行時にリアルタイム推論を可能にする「Robotics Transformer 1(RT-1)」を開発した。
2023年1月11日、DeepMindは、画像から世界モデルを学習し、それを使用して長期視点から考えて最適な行動を学習する事が出来る「DreamerV3」を発表した。
2023年5月11日、日本政府は首相官邸で、「AI戦略会議」（座長 松尾豊・東京大学大学院教授）の初会合を開いた。
2023年12月、Googleはさらに「Gemini」と呼ばれる人工知能基盤モデルを発表した。
この人工知能基盤モデルの特徴は、一般的なタスクにおいて専門家よりも高い正答率を示すことで、「Gemini」はついに専門家を超えたと宣伝されている。
2024年5月、OpenAIはGPT-4oをChatGPTに実装する。
開発者はGPT-4o、Gemini 1.5、Meta Chamelonなどが音声、動画、画像、テキストを同時に処理できる新しいAI基盤モデルによって、創造的なアプリを生成できるようになる。
2024年9月、OpenAIはOpenAI o1をChatGPTに実装する。
これにより、科学、コーディング、数学など、複雑な推論タスクを要する分野で特に優れた性能を持つ。
一般的に2018年頃はまだ、人工知能は肉体労働や単純作業を置き換え、芸術的・創造的仕事が「人間の領域」となると予想されてきたが、実際には2020年代前半から芸術的な分野へ急速に進出していると学術界でさえ予想できなかった節がある。
また人工知能の実用化後も残るとされた翻訳、意思決定、法律相談など高度なスキルを必要とする分野への応用も進んでいる。
一方で2023年時点では肉体労働や単純作業への利用は自動倉庫の制御、囲碁の盤面の映像から棋譜を作成するなど限定的な利用にとどまっている。
テスラ社は開発を進める二足歩行ロボットTesla Botに汎用人工知能を搭載し、単純労働を担当させると表明している。
人工知能は今、質問応答、意思決定支援、需要予測、音声認識、音声合成、機械翻訳、科学技術計算、文章要約など、各分野に特化したシステムやこれらを組み合わせたフレームワークが実用化された。
本節は今後の動向により更新される予定である。
科学とAI 機械学習や深層学習は、特化型AI（Artificial Narrow Intelligence：ANI）として科学の領域で活用されている。
タンパク質の折り畳みの高精度予測 自然言語処理によるRNAコドン配列の解析 気象物理過程式のパラメータ逆推定および気象モデルの最適統合 プレート境界の摩擦パラメータ推定、すべり量、発生サイクルを学習させることによる地震発生時期の予測 iPS細胞の生死などの状態、分化と未分化、がん化などの非標識判別 膨大な論文・公開特許から化合物の物性値や製法を抽出し知識ベース化できる化学検索エンジン 薬剤、分子探索、活性化合物構造の自動提案 宇宙の大規模構造の偏りをもたらした初期の物理パラメータを推定、宇宙全体の3Dシミュレーションの効率化 画像分類CNNを使用したマウス脳神経の自動分類、回路自動マッピング GANと回帰モデルによる複雑材料系(充填剤や添加剤)の特性予測 CAD設計手法の一つであるトポロジー最適化における、制約条件と解析結果の因果関係の抽出 第一原理計算(DFT計算)よりも10万倍以上高速な、55元素の任意の組み合わせの原子構造を高い精度で再現できる原子シミュレーターを用いた材料探索 流体力学の方程式を使わない、流体シミュレーション 医療診断用 視覚言語モデル ロボットの動作生成 科学的再現性の危機を解決するための論文の厳密性と透明性分析 コーディング自動化 哲学とAI 哲学・宗教・芸術 Googleは2019年3月、人工知能プロジェクトを倫理面で指導するために哲学者・政策立案者・経済学者・テクノロジスト等で構成される、AI倫理委員会を設置すると発表した。
しかし倫理委員会には反科学・反マイノリティ・地球温暖化懐疑論等を支持する人物も含まれており、Google社員らは解任を要請した。
4月4日、Googleは倫理委員会が「期待どおりに機能できないことが判明した」という理由で、委員会の解散を発表した。
東洋哲学をAIに吸収させるという三宅陽一郎のテーマに応じて、井口尊仁は「鳥居（TORII）」という自分のプロジェクトを挙げ、「われわれはアニミズムで、あらゆるものに霊的存在を見いだす文化があります」と三宅および立石従寛に語る。
アニミズム的人工知能論は現代アートや、「禅の悟りをどうやってAIにやらせるか」を論じた三宅の『人工知能のための哲学塾 東洋哲学篇』にも通じている。
元Googleエンジニアのアンソニー゠レバンドウスキーは2017年、AIを神とする宗教団体「Way of the Future（未来の道）」を創立している。
団体の使命は「人工知能（AI）に基づいたGodheadの実現を促進し開発すること、そしてGodheadの理解と崇拝を通して社会をより良くすることに貢献すること」と抽象的に表現されており、多くの海外メディアはSF映画や歴史などと関連付けて報道した。
UberとGoogleのWaymoは、レバンドウスキーが自動運転に関する機密情報を盗用したことを訴え裁判を行っている一方、レバンドウスキーはUberの元CEO（トラビス゠カラニック）に対し「ボットひとつずつ、我々は世界を征服するんだ」と発言するなど、野心的な振る舞いを示している。
2021年のメタ分析によれば、人工知能の設計はもちろん学際的なものであり、感覚の限界による偏見を避けるように注意しながら、宇宙のさまざまな物質や生物の特性を理解すべきである。
発明家レイ・カーツワイルが言うには、哲学者ジョン・サールが提起した強いAIと弱いAIの論争は、AIの哲学議論でホットな話題である。
哲学者ジョン・サールおよびダニエル・デネットによると、サールの「中国語の部屋」やネド・ブロックらの「中国脳」といった機能主義に批判的な思考実験は、真の意識が形式論理システムによって実現できないと主張している。
批判 脳のカオス現象に起因する問題 生命情報科学者・神経科学者の合原一幸編著『人工知能はこうして創られる』によれば、AIの急激な発展に伴って「技術的特異点、シンギュラリティ」の思想や哲学が一部で論じられているが、特異点と言っても「数学」的な話ではない。
前掲書は「そもそもシンギュラリティと関係した議論における『人間の脳を超える』という言明自体がうまく定義できていない」と記している。
確かに、脳を「デジタル情報処理システム」として捉える観点から見れば、シンギュラリティは起こり得るかもしれない。
しかし実際の脳はそのような単純なシステムではなく、デジタルとアナログが融合した「ハイブリッド系」であることが、脳神経科学の観察結果で示されている。
もちろん、人工知能が人間を超えることを期待すべきではないという学者もいるし、そもそもそうした人間対人工知能の戦争不安はメンタルヘルス上よくないので控えるべきである。
前掲書によると、神経膜では様々な「ノイズ」が存在し、このノイズ付きのアナログ量によって脳内のニューロンの「カオス」が生み出されているため、このような状況をデジタルで記述することは「極めて困難」と考えられている。
人間に設計された機構が他律システムとならざるを得ないことに起因する問題 人間に設計された人工知能などの機構は本質的に他律システムであり、設計の範囲内でしか動作できず、自発的な判断・行動を行っているわけではないため、過去の事例に制限されている。
他律システムは設計の範囲外にある未知の状況には対応できず、時間が経過するとともに設計当初からの環境の変化に沿わない不適切な処理を繰り返すようになる可能性がある（であるからこそ人間によるシステムの管理や更新が必要となる）。
他律システムの限界を超越する新しいシステム論（オートポイエーシスなど）で議論が続いているが、誰に設計されるわけでもなく地球上に登場し、未知の環境変化にも適応しながら進化を遂げた生命が持つような真の自律性をコード化できるかは不明である。
ただし、人間も物理現象に従う他律システムだと考えられ得る。
西垣通が『AI原論』などの書籍で、他者により設計される（つまり他者に律される）人工知能が真の自律性を獲得することはなく、技術的特異点の端緒となる再帰的な人工知能の「改良」の機能についても他者により行われた設計の範囲内でしか動作できないため、再帰的な「改良」後に意味のある動作が保たれる保証がないことや、人工知能に頼り切ると社会の硬直化を含む様々な問題が生じる可能性があることを繰り返し指摘している。
併せて西垣通は、汎用人工知能で人間を完全に代替する方向性ではなく、特化型人工知能と人間が共働する方向性を模索するべきと主張している。
文学・フィクション・SF（空想科学） 脚注 注釈 出典 参照文献 学術書・辞事典 合原一幸、牧野貴樹、金山博、河野崇、木脇太一、青野真士（著）合原一幸（編著）（編）『人工知能はこうして創られる』ウェッジ、2017年。
ISBN 978-4863101852。
市瀬龍太郎「【記事更新】教養知識としてのAI 〔第1回〕AIってなに？
」人工知能学会、2023年。
2023年9月3日閲覧。
江間有沙「人工知能社会のあるべき姿を求めて」『科学技術社会論研究』第16巻、2018年12月、9–14頁。
doi:10.24646/jnlsts.16.0_9。
ISSN 1347-5843。
北原保雄『明鏡国語辞典』（第二版版）、大修館書店、2010年。
ISBN 978-4469021172。
佐藤理史「人工知能」『日本大百科全書(ニッポニカ)』小学館・朝日新聞社・VOYAGE GROUP、2018年。
2018年8月16日閲覧。
人工知能は、「計算（computation）」という概念と「コンピュータ（computer）」という道具を用いて「知能」を研究する計算機科学（computer science）の一分野である。
誤解を恐れず平易にいいかえるならば、「これまで人間にしかできなかった知的な行為（認識、推論、言語運用、創造など）を、どのような手順（アルゴリズム）とどのようなデータ（事前情報や知識）を準備すれば、それを機械的に実行できるか」を研究する分野である。
人工知能学会「1997年度人工知能学会名簿」『人工知能学会誌』第12巻第5号、人工知能学会、1997年、653-808 (1-156)、doi:10.11517/jjsai.12.5_797。
新村出『広辞苑』（第七版版）、岩波書店、2018年1月12日。
ISBN 978-4000801317。
仙石正和「基礎研究を続ける大切さ（創立100周年記念特集「基礎・境界」が支えた100 年, これからの100年 ―― 未来 100 年を担うあなたへ贈る言葉）」『電子情報通信学会誌（The journal of the Institute of Electronics, Information and Communication Engineers）』第100巻第6号、電子情報通信学会、2017年、431–439頁。
全卓樹『エキゾティックな量子：不可思議だけど意外に近しい量子のお話』東京大学出版会、2014年。
ISBN 978-4130636070。
野家啓一「科学時代の哲学：哲学は「二流の科学」か？
」『哲学の探求』第29巻、哲学若手研究者フォーラム、2002年、31-42頁。
トルケル・フランセーン 著、田中一之 訳『ゲーデルの定理：利用と誤用の不完全ガイド』みすず書房、2011年。
ISBN 978-4622075691。
松尾豊「深層学習と人工知能」『認知科学』第28巻第2号、2021年6月、299–307頁。
doi:10.11225/cs.2021.012。
ISSN 1341-7924。
桃内佳雄「人工知能」『日本大百科全書(ニッポニカ)』小学館・朝日新聞社・VOYAGE GROUP、2017年。
2017年12月31日閲覧。
計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野 ASCII.jp「人工知能」『ASCII.jpデジタル用語辞典』ASCII.jp・朝日新聞社・VOYAGE GROUP、2018年。
https://kotobank.jp/word/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD-4702#SCII.jp.E3.83.87.E3.82.B8.E3.82.BF.E3.83.AB.E7.94.A8.E8.AA.9E.E8.BE.9E.E5.85.B8。
2018年8月16日閲覧。
「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術。
」 Copeland, B.J. (2023-09-02). “artificial intelligence”. Encyclopedia Britannica. Encyclopædia Britannica, Inc.. https://www.britannica.com/technology/artificial-intelligence 2023年9月3日閲覧。
Geraci, Robert M. (2012年). Apocalyptic AI: Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality (reprinted ed.). Oxford University Press. ISBN 9780199964000。
Russell, Stuart; Norvig, Peter (2022). Artificial Intelligence: A Modern Approach (Fourth Global ed.). Pearson. ISBN 978-1292401133 教育研究機関・研究開発機関 東京大学 工学部 機械情報工学科『東京大学 工学部 機械情報工学科』東京大学 工学部、2021年。
https://web.archive.org/web/20210621164347/http://www.t.u-tokyo.ac.jp/eng/innovator/pre/dept/mechano-informatics.html。
2021年2月25日閲覧。
東京大学 工学部 電子情報工学科『東京大学 工学部 電子情報工学科』東京大学 工学部、2021年。
https://web.archive.org/web/20210621164413/http://www.t.u-tokyo.ac.jp/eng/innovator/pre/dept/communication-engineering.html。
2021年2月25日閲覧。
東京大学 理学部 情報科学科、東京大学大学院 情報理工学系研究科 コンピュータ科学専攻『人工知能と機械学習』東京大学・東京大学大学院、2021年。
https://www.is.s.u-tokyo.ac.jp/shingaku/highschool/ai.html。
2021年2月25日閲覧。
Muehlhauser, Luke (2013年10月19日). “Russell and Norvig on Friendly AI”. Machine Intelligence Research Institute. 2023年9月3日閲覧。
政府機関 欧州連合日本政府代表部『EU AI規則の概要』（PDF）（レポート）欧州連合〈英語公式条文の翻訳〉、2024年。
https://www.eu.emb-japan.go.jp/files/100741144.pdf。
総務省『令和6年版 情報通信白書 PDF全体版』（レポート）総務省、2024年。
https://www.soumu.go.jp/johotsusintokei/whitepaper/ja/r06/pdf/index.html。
報道 高橋ミレイ (2019年). “人工知能が禅の「悟り」を開く日は訪れるのか？
：三宅陽一郎×井口尊仁×立石従寛 鼎談（後編）”. WIRED. WIRED. 2019年2月6日閲覧。
塚本紺 (2017年). “神はAI？
元Googleエンジニアが宗教団体を創立”. livedoorニュース. ギズモード・ジャパン. 2019年2月6日閲覧。
Will Knight (2019年). “グーグルが新設した「AI倫理委員会」に社員が猛反発した理由”. MITテクノロジーレビュー. 株式会社角川アスキー総合研究所. 2019年4月6日閲覧。
Strickland, Eliza (October 2021). “The Turbulent Past and Uncertain Future of AI”. IEEE Spectrum 58 (10). doi:10.1109/MSPEC.2021.9563956. 関連文献 英語資料 関連項目 人工知能企業の一覧 人工知能開発プロジェクト一覧 教育研究・研究開発 理学 - 工学 - 理工学 - 応用科学 量子コンピューティング - 計算機科学 - 計算機工学 - 情報科学 - 情報工学 - ソフトウェア工学 数学 - 数理論理学／現代論理学 - 数理工学 ゲーデルの不完全性定理 - チューリングマシン - アルゴリズム 研究開発・応用科学 開発事例・応用事例 研究課題 関連分野 深層学習・機械学習に関連する数学、物理学 AIに関する哲学的項目 外部リンク 人工知能のやさしい説明「What's AI」 - 一般社団法人 人工知能学会 人工知能（AI）とは？
マイクロソフトが解説する人工知能 マイクロソフト Copilot 人工知能ハンドブック（英語） 「Can Machine Think?」（英語） - ラジオ番組「フィロソフィー・トーク」のバックナンバー。
テーマ：「機械は考えられるのか？
」 ゲスト：ジョン・サール、ジョン・マッカーシー、59分08秒。